[PROCESS]
experiment_ID: L${NETWORK:num_layers}_H${NETWORK:layer_size}_DO${TRAINING:dropout}_L1${TRAINING:l1_regularization}_L2${TRAINING:l2_regularization}_B${TRAINING:batch_size}_LR${TRAINING:learning_rate} #empty means auto name
checkpoint_every: 10000 # in number of iterations
validation_interval: 20 # in number of iterations, default if omitted:15
initialize_with_checkpoint: # path like: checkpoints/enigma/training.ckpt-10


[PATHS]
training_file: data/NN_train_sud_rsmall.csv
validation_file: data/valid_fixed.csv
checkpoint_dir: checkpoints/enigma
log_folder: log/gr


[NETWORK]
num_layers: 1
layer_size: 20  #previously "number of hidden units"
residual: False #default: False
batch_norm: False #Batch normalization, default: True

[FEATURES]
columns: 1:-1


[TASK0] #name of section has to begin with TASK
type: classification
ground_truth_column: -1 #-1 for last column
num_classes: 2
weight: 1 #loss weight, how important is task compared to other tasks


#[TASK1] #This task is commented out
#type: linear
#ground_truth_column: -1


[TRAINING]
num_epochs: 1000 #set to 0 to do no training
learning_rate: 0.01
batch_size: 16
validation_batch_size: 50
optimizer: adam #one of [vanilla, adam, adagrad, rmsprop]
l1_regularization: 0 #default if omitted : 0
l2_regularization: 0 #default if omitted : 0
dropout: 0.5 #default if omitted : 1
#stratified_sampling: TASK0
#Optional, if specified , makes batching do weighted sampling on input data ,
#such as all classes are represented equally during training.
#Value must specifiy a classification task's name, e.g. TASK0

#[TEST]
#optional. To omit testing , please remove the whole [TEST] section
#Testing will always happen after all training epochs are done
#test_file:  data/enigma_test_sex(age).csv
#write_predictions_to: /tmp/test_softmax_outputs.txt
#batch_size: 700 #set to number of rows of test file to test whole file

